{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Performance_metrics_Instructions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopaiml/AppliedAI/blob/master/5_Performance_metrics_Instructions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV",
        "colab_type": "text"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# other than these two you should not import any other packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTPi8B4sT8fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import operator\n",
        "\n",
        "def auc_from_fpr_tpr(fpr, tpr, trapezoid=False):\n",
        "    inds = [i for (i, (s, e)) in enumerate(zip(fpr[: -1], fpr[1: ])) if s != e] + [len(fpr) - 1]\n",
        "    fpr, tpr = fpr[inds], tpr[inds]\n",
        "    area = 0\n",
        "    ft = zip(fpr, tpr)\n",
        "    for p0, p1 in enumerate(zip(ft[: -1], ft[1: ])):\n",
        "        area += (p1[0] - p0[0]) * ((p1[1] + p0[1]) / 2 if trapezoid else p0[1])\n",
        "    return area "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFLW7oBQvnt",
        "colab_type": "code",
        "outputId": "3961b57a-9cbd-4e71-fb21-f18d8ed6a0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "# write your code here\n",
        "df = pd.read_csv ('/content/5_a.csv')\n",
        "df.loc[df[\"proba\"] >= 0.5, 'y_pred'] = 1\n",
        "df.loc[df[\"proba\"] < 0.5, 'y_pred'] = 0\n",
        "#print(df)\n",
        "#Compute confuse matrix\n",
        "actual = df['y'].to_numpy()\n",
        "actual=actual.astype(int)\n",
        "prob=df['proba'].to_numpy()\n",
        "predicted = df['y_pred'].to_numpy()\n",
        "predicted=predicted.astype(int)\n",
        "#print(\"actual\",actual)\n",
        "cm = np.zeros((2,2))\n",
        "#print(cm.shape)\n",
        "trp=0\n",
        "trn=0\n",
        "flp=0\n",
        "fln=0\n",
        "for a, p in zip(actual, predicted):\n",
        "    if a== 1 and p==1:\n",
        "        trp+=1\n",
        "    elif a== 0 and p==0:\n",
        "        trn+=1  \n",
        "    if a== 0 and p==1:\n",
        "        flp+=1  \n",
        "    if a== 1 and p==0:\n",
        "        fln+=1\n",
        "    cm[a][p] += 1\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "conf_matrix=[[trn,flp],[fln,trp]]\n",
        "cf_matrix=np.array(conf_matrix)\n",
        "print(conf_matrix)\n",
        "print(cm)\n",
        "print(\"precision\")\n",
        "prec=trp/(trp+flp)\n",
        "print(prec)\n",
        "print(\"recall\")\n",
        "recall=trp/(trp+fln)\n",
        "print(recall)\n",
        "print(\"F1 Score\")\n",
        "f1=((2*prec*recall)/(prec+recall))\n",
        "print(f1)\n",
        "print(\"Accuracy Score\")\n",
        "accu=(trp+trn)/(trp+flp+fln+trn)\n",
        "print(accu)\n",
        "\n",
        "FP = cf_matrix.sum(axis=0) - np.diag(cf_matrix)  \n",
        "FN = cf_matrix.sum(axis=1) - np.diag(cf_matrix)\n",
        "TP = np.diag(cf_matrix)\n",
        "TN = cf_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "\n",
        "TPR = TP/(TP+FN)\n",
        "FPR = FP/(FP+TN)\n",
        "print(\"TPR\",TPR)\n",
        "print(\"FPR\",FPR)\n",
        "print(\"numpy.trapz(tpr_array, fpr_array)\",np.trapz(tpr,fpr))\n",
        "# also get the accuracy score\n",
        "accuracy = (actual == predicted).sum() / float(len(actual))\n",
        "print(\"Accuracy scores\",accuracy)\n",
        "#Using sklearn lib\n",
        "from sklearn.metrics import precision_score, \\\n",
        "    recall_score, confusion_matrix, classification_report, \\\n",
        "    accuracy_score, f1_score,roc_curve,auc\n",
        "print(\"sklearn Confusion Matrix\",confusion_matrix(actual, predicted))\n",
        "conf_matrix=confusion_matrix(actual, predicted)\n",
        "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
        "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
        "TP = np.diag(conf_matrix)\n",
        "TN = conf_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "\n",
        "TPR = TP/(TP+FN)\n",
        "FPR = FP/(FP+TN)\n",
        "print(\"TPR\",TPR)\n",
        "print(\"FPR\",FPR)\n",
        "print(\"F1 score\",f1_score(actual, predicted))\n",
        "print(\"Recall\",recall_score(actual, predicted))\n",
        "print(\"preci\",precision_score(actual, predicted))\n",
        "print(\"accuracy\",accuracy_score(actual, predicted))\n",
        "fpr, tpr,thresholds = roc_curve(actual,predicted)\n",
        "print(\"thresholds\",thresholds)\n",
        "print(\"fpr\",fpr)\n",
        "print(\"tpr\",tpr)\n",
        "print(\"fpr , tpr, thresholds\",roc_curve(actual,predicted))\n",
        "print(\"auc calculation\",auc(fpr, tpr))\n",
        "print(\"numpy.trapz(tpr_array, fpr_array)\",np.trapz(tpr,fpr))\n",
        "#######\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[0, 100], [0, 10000]]\n",
            "[[    0.   100.]\n",
            " [    0. 10000.]]\n",
            "precision\n",
            "0.9900990099009901\n",
            "recall\n",
            "1.0\n",
            "F1 Score\n",
            "0.9950248756218906\n",
            "Accuracy Score\n",
            "0.9900990099009901\n",
            "TPR [0. 1.]\n",
            "FPR [0. 1.]\n",
            "numpy.trapz(tpr_array, fpr_array) 0.5\n",
            "Accuracy scores 0.9900990099009901\n",
            "sklearn Confusion Matrix [[    0   100]\n",
            " [    0 10000]]\n",
            "TPR [0. 1.]\n",
            "FPR [0. 1.]\n",
            "F1 score 0.9950248756218906\n",
            "Recall 1.0\n",
            "preci 0.9900990099009901\n",
            "accuracy 0.9900990099009901\n",
            "thresholds [2 1]\n",
            "fpr [0. 1.]\n",
            "tpr [0. 1.]\n",
            "fpr , tpr, thresholds (array([0., 1.]), array([0., 1.]), array([2, 1]))\n",
            "auc calculation 0.5\n",
            "numpy.trapz(tpr_array, fpr_array) 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTRzqEPCKgyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "e6035da6-37c7-461a-fb60-9e99f10c2829"
      },
      "source": [
        "# write your code\n",
        "# write your code here\n",
        "df = pd.read_csv ('/content/5_b.csv')\n",
        "df.loc[df[\"proba\"] >= 0.5, 'y_pred'] = 1\n",
        "df.loc[df[\"proba\"] < 0.5, 'y_pred'] = 0\n",
        "#print(df)\n",
        "#Compute confuse matrix\n",
        "actual = df['y'].to_numpy()\n",
        "actual=actual.astype(int)\n",
        "prob=df['proba'].to_numpy()\n",
        "predicted = df['y_pred'].to_numpy()\n",
        "predicted=predicted.astype(int)\n",
        "#print(\"actual\",actual)\n",
        "cm = np.zeros((2,2))\n",
        "#print(cm.shape)\n",
        "trp=0\n",
        "trn=0\n",
        "flp=0\n",
        "fln=0\n",
        "for a, p in zip(actual, predicted):\n",
        "    if a== 1 and p==1:\n",
        "        trp+=1\n",
        "    elif a== 0 and p==0:\n",
        "        trn+=1  \n",
        "    if a== 0 and p==1:\n",
        "        flp+=1  \n",
        "    if a== 1 and p==0:\n",
        "        fln+=1\n",
        "    cm[a][p] += 1\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "conf_matrix=[[trn,flp],[fln,trp]]\n",
        "cf_matrix=np.array(conf_matrix)\n",
        "print(conf_matrix)\n",
        "print(cm)\n",
        "print(\"precision\")\n",
        "prec=trp/(trp+flp)\n",
        "print(prec)\n",
        "print(\"recall\")\n",
        "recall=trp/(trp+fln)\n",
        "print(recall)\n",
        "print(\"F1 Score\")\n",
        "f1=((2*prec*recall)/(prec+recall))\n",
        "print(f1)\n",
        "print(\"Accuracy Score\")\n",
        "accu=(trp+trn)/(trp+flp+fln+trn)\n",
        "print(accu)\n",
        "\n",
        "FP = cf_matrix.sum(axis=0) - np.diag(cf_matrix)  \n",
        "FN = cf_matrix.sum(axis=1) - np.diag(cf_matrix)\n",
        "TP = np.diag(cf_matrix)\n",
        "TN = cf_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "\n",
        "TPR = TP/(TP+FN)\n",
        "FPR = FP/(FP+TN)\n",
        "print(\"TPR\",TPR)\n",
        "print(\"FPR\",FPR)\n",
        "print(\"numpy.trapz(tpr_array, fpr_array)\",np.trapz(tpr,fpr))\n",
        "# also get the accuracy score\n",
        "accuracy = (actual == predicted).sum() / float(len(actual))\n",
        "print(\"Accuracy scores\",accuracy)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[9761, 239], [45, 55]]\n",
            "[[9761.  239.]\n",
            " [  45.   55.]]\n",
            "precision\n",
            "0.1870748299319728\n",
            "recall\n",
            "0.55\n",
            "F1 Score\n",
            "0.2791878172588833\n",
            "Accuracy Score\n",
            "0.9718811881188119\n",
            "TPR [0.9761 0.55  ]\n",
            "FPR [0.45   0.0239]\n",
            "numpy.trapz(tpr_array, fpr_array) 0.5\n",
            "Accuracy scores 0.9718811881188119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
        "<br>\n",
        "\n",
        "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # write your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
        "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    }
  ]
}