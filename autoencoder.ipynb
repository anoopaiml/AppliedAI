{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopaiml/AppliedAI/blob/master/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-OZTb7Pyl7N",
        "colab_type": "text"
      },
      "source": [
        "**Auto Encoder Implementation**\n",
        "\n",
        "https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726\n",
        "\n",
        "Example of the input/output image from the MNIST dataset to an autoencoder\n",
        "\n",
        "## Autoencoder Components:\n",
        "# Autoencoders consists of 4 main parts:\n",
        "## 1- Encoder: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n",
        "## 2- Bottleneck: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.\n",
        "## 3- Decoder: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n",
        "## 4- Reconstruction Loss: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olZCnOI3yldG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "46361d04-fffb-47d4-f2bc-98336b2584c6"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_joBnPGf1NlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f08935db-c9d8-43b8-cff8-fabf1209d9f1"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "train_x = x_train.reshape(60000, 784) / 255\n",
        "val_x = x_test.reshape(10000, 784) / 255"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbfKRVA_E7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7b8b533-09f5-4a53-87de-ece3e8724420"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(train_x.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(60000, 784)\n",
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNYAOJ_Z1UJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9a0a4dbc-c947-4c3b-bc86-1b52159eef69"
      },
      "source": [
        "autoencoder = Sequential()\n",
        "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(512,  activation='elu'))\n",
        "autoencoder.add(Dense(784,  activation='sigmoid'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLLZLiKa1nIB",
        "colab_type": "code",
        "outputId": "2930306a-2b59-4dbe-978a-60d6066b2ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
        "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10, verbose=1, validation_data=(val_x, val_x))\n",
        "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
        "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
        "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
        "encoding_dim = 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0741 - val_loss: 0.0473\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0397 - val_loss: 0.0339\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0310 - val_loss: 0.0279\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0271 - val_loss: 0.0252\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0248 - val_loss: 0.0233\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0230 - val_loss: 0.0218\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0217 - val_loss: 0.0208\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0207 - val_loss: 0.0199\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0199 - val_loss: 0.0192\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.0192 - val_loss: 0.0186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG3QUW7L1q2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return the decoder\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder = autoencoder.layers[-3](encoded_input)\n",
        "decoder = autoencoder.layers[-2](decoder)\n",
        "decoder = autoencoder.layers[-1](decoder)\n",
        "decoder = Model(encoded_input, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTYFRa8g10Cu",
        "colab_type": "code",
        "outputId": "f8ae3b24-2677-4b05-c163-867ef3256d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
        "img = image.load_img(\"/content/mario.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
        "input_img = image.img_to_array(img)\n",
        "inputs = input_img.reshape(1,784)\n",
        "print(inputs.shape)\n",
        "print(train_x.shape)\n",
        "target_data = autoencoder.predict(inputs)\n",
        "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
        "print(dist)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 784)\n",
            "(60000, 784)\n",
            "[5329.1064]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yibPkdqS4IHn",
        "colab_type": "code",
        "outputId": "7fab8ce7-952e-4f88-9ecf-7c7bfdcd2578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
        "img = image.load_img(\"/content/SEVEN.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
        "input_img = image.img_to_array(img)\n",
        "print(input_img.shape)\n",
        "plt.imshow(img)\n",
        "inputs = input_img.reshape(1,784)\n",
        "target_data = autoencoder.predict(inputs)\n",
        "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
        "print(dist)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "[1954.0082]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ-atk2t5FUw",
        "colab_type": "code",
        "outputId": "12f5525f-389e-4e9a-e7e2-693e90e40142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# The code below is from the Keras Blogs\n",
        "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "#Print one image to see the noise\n",
        "plt.imshow(x_test_noisy[1].reshape(28, 28))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbfe47fca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPMFiJ/IEi53IEyx2Ik+w2Ik88X+cm/UbPZjKxwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZDDYfDc5aFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "input_img = Input(shape=(28,28,1))\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "nn = MaxPooling2D((2, 2), padding='same')(nn)\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znV5bjZt56tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "nn = UpSampling2D((2, 2))(nn)\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
        "nn = UpSampling2D((2, 2))(nn)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45w_rjs_TQEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "5c5b3416-e3b2-4fca-aa14-68df1bd1d68a"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_train_noisy.shape)\n",
        "print(x_test.shape)\n",
        "print(x_test_noisy.shape)\n",
        "x_train_noisy=x_train_noisy.reshape(60000,28,28)\n",
        "x_test_noisy=x_test_noisy.reshape(60000,28,28)\n",
        "print(x_train_noisy)\n",
        "print(x_test_noisy)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1a26ab5178a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_train_noisy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_test_noisy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7840000 into shape (60000,28,28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-yv_Bw06ETh",
        "colab_type": "code",
        "outputId": "af753654-32c6-46cc-c3b6-fe06966d2abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train_noisy, x_train_noisy,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                validation_data=(x_test_noisy, x_test_noisy))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-319a45b3cef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 validation_data=(x_test_noisy, x_test_noisy))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have 4 dimensions, but got array with shape (60000, 28, 28)"
          ]
        }
      ]
    }
  ]
}