{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopaiml/AppliedAI/blob/master/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-OZTb7Pyl7N",
        "colab_type": "text"
      },
      "source": [
        "**Auto Encoder Implementation**\n",
        "\n",
        "https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726\n",
        "\n",
        "Example of the input/output image from the MNIST dataset to an autoencoder\n",
        "\n",
        "## Autoencoder Components:\n",
        "# Autoencoders consists of 4 main parts:\n",
        "## 1- Encoder: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n",
        "## 2- Bottleneck: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.\n",
        "## 3- Decoder: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n",
        "## 4- Reconstruction Loss: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olZCnOI3yldG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "4cfbc24e-1b72-4d50-f65d-0dc8d24ae353"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_joBnPGf1NlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0a7be01c-422a-476c-be83-3375c895cfdd"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "train_x = x_train.reshape(60000, 784) / 255\n",
        "val_x = x_test.reshape(10000, 784) / 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbfKRVA_E7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_test.shape)\n",
        "print(train_x.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNYAOJ_Z1UJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = Sequential()\n",
        "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(512,  activation='elu'))\n",
        "autoencoder.add(Dense(784,  activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLLZLiKa1nIB",
        "colab_type": "code",
        "outputId": "16ce4c58-76de-4b6f-d61b-31a3ba153f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
        "trained_model = autoencoder.fit(train_x, y_train, batch_size=1024, epochs=10, verbose=1, validation_data=(val_x, val_x))\n",
        "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
        "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
        "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
        "encoding_dim = 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-524ab66ce1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bottleneck representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_10 to have shape (784,) but got array with shape (1,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG3QUW7L1q2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return the decoder\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder = autoencoder.layers[-3](encoded_input)\n",
        "decoder = autoencoder.layers[-2](decoder)\n",
        "decoder = autoencoder.layers[-1](decoder)\n",
        "decoder = Model(encoded_input, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTYFRa8g10Cu",
        "colab_type": "code",
        "outputId": "8e36e288-d1e7-46aa-ca34-e8d006a2ec43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
        "img = image.load_img(\"/content/mario.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
        "input_img = image.img_to_array(img)\n",
        "inputs = input_img.reshape(1,784)\n",
        "target_data = autoencoder.predict(inputs)\n",
        "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
        "print(dist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5328.317]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yibPkdqS4IHn",
        "colab_type": "code",
        "outputId": "711f1089-4c38-42fb-a54b-5906db74ef11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
        "img = image.load_img(\"/content/eight.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
        "input_img = image.img_to_array(img)\n",
        "inputs = input_img.reshape(1,784)\n",
        "target_data = autoencoder.predict(inputs)\n",
        "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
        "print(dist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6674.833]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ-atk2t5FUw",
        "colab_type": "code",
        "outputId": "44d137da-1d12-4211-b02f-03f9a5cfee18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# The code below is from the Keras Blogs\n",
        "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "import matplotlib.pyplot as plt\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "#Print one image to see the noise\n",
        "plt.imshow(x_test_noisy[1].reshape(28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff5f4c80a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni53IEyx2Ik/8P1ma07CFM5kVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZDDYfDc5aFZ",
        "colab_type": "code",
        "outputId": "3c41cdf4-0035-4bc4-81a7-4421ecec8271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "nn = MaxPooling2D((2, 2), padding='same')(nn)\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znV5bjZt56tG",
        "colab_type": "code",
        "outputId": "d9d0a5e0-594e-4c77-c038-5062f6d60045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "nn = UpSampling2D((2, 2))(nn)\n",
        "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
        "nn = UpSampling2D((2, 2))(nn)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-yv_Bw06ETh",
        "colab_type": "code",
        "outputId": "e5ee91c4-ff4e-48e9-874a-a2cc9f115f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=16,\n",
        "                validation_data=(x_test_noisy, x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-36d2fc77726d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 validation_data=(x_test_noisy, x_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_3 to have 4 dimensions, but got array with shape (60000, 28, 28)"
          ]
        }
      ]
    }
  ]
}